{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3dce09b7-f05b-46eb-b8ae-7f7481dbd2be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# main libs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# testing formants\n",
    "import feather\n",
    "import pyarrow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0869c872-2b4d-4540-90aa-cd9819a0d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set folder for files\n",
    "folder = 'bench_files'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbe50eef-9daa-45b6-a448-416d101d4e39",
   "metadata": {},
   "source": [
    "# Creating dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc9f1eaa-28c3-4b18-8c9f-6d2592856ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SynthDF(pd.DataFrame):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        \n",
    "    @property\n",
    "    def _constructor(self):\n",
    "        return SynthDF\n",
    "    \n",
    "    @classmethod\n",
    "    def create_data(cls, size):\n",
    "        \"\"\"\n",
    "        Create a synthetic DataFrame with random data.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        size : int\n",
    "            Number of rows in the DataFrame.\n",
    "        \"\"\"\n",
    "        df = cls()\n",
    "        \n",
    "        # dates\n",
    "        dates = pd.date_range('2024-01-01', '2024-12-31')\n",
    "        df['date'] = np.random.choice(dates, size)\n",
    "        # int data\n",
    "        df['tournament_id'] = np.arange(size)\n",
    "        df['team_id'] = np.random.randint(1, 1000, size)\n",
    "        df['members'] = np.random.randint(1, 10, size)\n",
    "        # categorical data\n",
    "        df['location'] = np.random.choice(['Asia', 'Europe', 'Africa', 'America', 'Oceania'], size)\n",
    "        df['importance'] = np.random.choice(['local', 'minor', 'major'], size)\n",
    "\n",
    "        # float data\n",
    "        df['avg_age'] = np.random.randint(100, 500, size) / 10\n",
    "        df['prize'] = np.random.randint(10000, 10000000, size) / 100\n",
    "        df['prob'] = np.random.uniform(0, 1, size)\n",
    "        # bool data\n",
    "        df['win'] = np.random.choice([True, False], size)\n",
    "        \n",
    "        return df\n",
    "\n",
    "    def dtypes_setter(self):\n",
    "        \"\"\"\n",
    "        Set data types for columns in a synthetic DataFrame.\n",
    "\n",
    "        - Integers: 'tournament_id' ('int32'), 'team_id' ('int16'), 'members' ('int8').\n",
    "        - Categorical: 'location', 'importance'.\n",
    "        - Floats: 'avg_age' ('float16'), 'prize' ('float32'), 'prob' ('float32').\n",
    "        \"\"\"\n",
    "\n",
    "        # int data\n",
    "        self['tournament_id'] = self['tournament_id'].astype('int32')\n",
    "        self['team_id'] = self['team_id'].astype('int16')\n",
    "        self['members'] = self['members'].astype('int8')\n",
    "\n",
    "        # categorical data\n",
    "        self['location'] = self['location'].astype('category')\n",
    "        self['importance'] = self['importance'].astype('category')\n",
    "\n",
    "        # float data\n",
    "        self['avg_age'] = self['avg_age'] .astype('float32')\n",
    "        self['prize'] = self['prize'].astype('float32')\n",
    "        self['prob'] = self['prob'].astype('float32')\n",
    "\n",
    "    def benchmark(self, f_name, write_method, read_method, kwargs_write={}, kwargs_read={}):\n",
    "        \"\"\"\n",
    "        Benchmark the performance and space requirements of writing and reading a DataFrame.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        f_name : str\n",
    "            The name of the file to be used for benchmarking.\n",
    "        write_method : callable\n",
    "            The method used to write the DataFrame to a file.\n",
    "        read_method : callable\n",
    "            The method used to read the DataFrame from a file.\n",
    "        kwargs_write : dict, optional\n",
    "            Additional keyword arguments for the write method.\n",
    "        kwargs_read : dict, optional\n",
    "            Additional keyword arguments for the read method.\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        dict\n",
    "            A dictionary containing benchmark results.\n",
    "            - 'format': The file format extension.\n",
    "            - 'df_size': The size identifier of the DataFrame.\n",
    "            - 'write': Timing information for the write operation.\n",
    "            - 'read': Timing information for the read operation.\n",
    "            - 'size': The size of the file on disk.\n",
    "            - 'metadata': Whether metadata (data types) is preserved in the read operation.\n",
    "        \"\"\"\n",
    "        # set path to file \n",
    "        file = os.path.join(folder, f_name)\n",
    "\n",
    "        # bench write time\n",
    "        write = %timeit -o write_method(self, file, **kwargs_write)\n",
    "\n",
    "        # bench read time\n",
    "        read = %timeit -o read_method(file, **kwargs_read)\n",
    "\n",
    "        # bench size of file\n",
    "        space = os.path.getsize(file)\n",
    "        print(f'{space} bytes (required space)')\n",
    "\n",
    "        # metadata\n",
    "        new_df = read_method(file, **kwargs_read)\n",
    "        saved_metadata = new_df.dtypes == self.dtypes\n",
    "        print('metadata is saved' if saved_metadata.all() else 'metadata is NOT saved')\n",
    "\n",
    "        result = {\n",
    "            'format': f_name.split('.')[-1],\n",
    "            'df_size': f_name.split('_')[0],\n",
    "            'write': write.average,\n",
    "            'read': read.average,\n",
    "            'size': space,\n",
    "            'metadata': saved_metadata.all()\n",
    "        }\n",
    "\n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6101dc15-d719-43b5-a5fe-7985fc742281",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data synthesis\n",
    "df_small = SynthDF.create_data(100000)\n",
    "df_medium = SynthDF.create_data(1000000)\n",
    "df_large = SynthDF.create_data(10000000)\n",
    "\n",
    "# change dtypes\n",
    "df_small.dtypes_setter()\n",
    "df_medium.dtypes_setter()\n",
    "df_large.dtypes_setter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ba023bc3-f036-4f76-9a8b-bc38de02ac46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init df for result\n",
    "result = pd.DataFrame(columns=['format','df_size','write', 'read', 'size', 'metadata'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54fa70a-2a1a-456b-a9d4-463e52c111c6",
   "metadata": {},
   "source": [
    "# CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a9203681-a4f9-4da1-bc5f-55c7885d005c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.72 s ± 291 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "168 ms ± 12 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "6670787 bytes (required space)\n",
      "metadata is NOT saved\n"
     ]
    }
   ],
   "source": [
    "temp = df_small.benchmark(\n",
    "    f_name='s_csv.csv', \n",
    "    write_method=pd.DataFrame.to_csv, \n",
    "    read_method=pd.read_csv,\n",
    "    kwargs_write={'index': False}\n",
    ")\n",
    "result = pd.concat([result, pd.DataFrame.from_dict(temp, orient='index').transpose()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1492881-6356-4395-8817-22e1f285c23e",
   "metadata": {},
   "source": [
    "# JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc7769b8-9d74-461f-b45b-d6e4df462d8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189 ms ± 3.95 ms per loop (mean ± std. dev. of 7 runs, 10 loops each)\n",
      "941 ms ± 24.5 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n",
      "16626447 bytes (required space)\n",
      "metadata is NOT saved\n"
     ]
    }
   ],
   "source": [
    "temp = df_small.benchmark(\n",
    "    f_name='s_json.json', \n",
    "    write_method=pd.DataFrame.to_json, \n",
    "    read_method=pd.read_json,\n",
    ")\n",
    "result = pd.concat([result, pd.DataFrame.from_dict(temp, orient='index').transpose()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1adcd8a3-8882-43b5-89f5-5f33a8bd79a7",
   "metadata": {},
   "source": [
    "# Pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6043ee2a-6f48-413c-9e78-feda82b4d9b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.55 ms ± 155 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2.1 ms ± 193 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "3002037 bytes (required space)\n",
      "metadata is saved\n"
     ]
    }
   ],
   "source": [
    "temp = df_small.benchmark(\n",
    "    f_name='s_pickle.pickle', \n",
    "    write_method=pd.DataFrame.to_pickle, \n",
    "    read_method=pd.read_pickle,\n",
    ")\n",
    "result = pd.concat([result, pd.DataFrame.from_dict(temp, orient='index').transpose()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adb53539-d555-4270-a576-f16e539e2626",
   "metadata": {},
   "source": [
    "# Feather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "88bcea07-c141-40f7-9961-f8ee175f4b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.07 ms ± 90.5 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "6.86 ms ± 106 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "2189170 bytes (required space)\n",
      "metadata is saved\n"
     ]
    }
   ],
   "source": [
    "temp = df_small.benchmark(\n",
    "    f_name='s_feather.feather', \n",
    "    write_method=pd.DataFrame.to_feather, \n",
    "    read_method=pd.read_feather,\n",
    ")\n",
    "result = pd.concat([result, pd.DataFrame.from_dict(temp, orient='index').transpose()], ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ef66f16-b78b-4f39-b7d6-5f7132176a4b",
   "metadata": {},
   "source": [
    "# Parquet\n",
    "`\n",
    "!pip istall pyarrow\n",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5273143d-0593-4d7d-9adf-924847d1a66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# temp = df_small.benchmark(\n",
    "#     f_name='s_parquet.parquet', \n",
    "#     write_method=pd.DataFrame.to_parquet, \n",
    "#     read_method=pd.read_parquet,\n",
    "# )\n",
    "# result = pd.concat([result, pd.DataFrame.from_dict(temp, orient='index').transpose()], ignore_index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
